<!DOCTYPE html>
<html>
<head>
    <title>wgertler | Tumbling Down the Rabbit Hole</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="William Gertler">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="/css/kube.css" />
    <link rel="stylesheet" href="/css/all.min.css" />
    <link rel="stylesheet" href="/css/custom.css" />
    <link rel="icon"       href="/img/favicon.png" />
    <script src="/mathjax/load-mathjax.js" async></script>
</head>

<body>
	<!-- Navigation -->
	<div class="main-nav">
		<div class="container">
			<header class="group top-nav">
				<nav class="navbar logo-w navbar-left" >
					<a class="logo" href="/">wgertler</a>
				</nav>
				<div class="navigation-toggle" data-tools="navigation-toggle" data-target="#navbar-1">
				    <span class="logo">wgertler</span>
				</div>
			    <nav id="navbar-1" class="navbar item-nav navbar-right">
				    <ul>
				        <li><a href="/">Home</a></li>
				        <li><a href="/about/">About</a></li>
				        <li><a href="/articles/">Articles</a></li>
				    </ul>
				</nav>
			</header>
		</div>
	</div>

	<!-- Content -->
<div class="content">
    <div class="container">
        <!-- Post -->
        <div class="post">
            <!-- Heading -->
                <h1>A Brief Sojourn in Network Security</h1>
                <h4>March, 2021</h4>
            <hr>
            <div class="in-content">

				<p>
					I know so much more about wikipedia now than I ever meant
                    to learn. I've probably forgotten more about wikipedia's
                    inner workings than most of its power-users and top
                    contributors ever need to learn. Over the past few years,
                    I've spent a lot of moonlighting hours decompressing from
                    physics, stuck in bus stations, frustrated at other
                    projects and taking out that frustration on what this
                    project could have been &mdash; only to find that every
                    question I and my collaborator had seeked to ask had been
                    answered more than a year before we'd begun working on it,
                    most comprehensively in the doctoral thesis of
                    <a href="https://uwspace.uwaterloo.ca/bitstream/handle/10012/10123/Wang_Tao.pdf?sequence=3&isAllowed=y">
                        Tao Wang</a> in 2015, done at the CrySP lab at
                    Waterloo, and brought to my attention recently by friend
                    (and CrySP alum)
                    <a href="https://annalorimer.com/">Anna Lorimer</a>. Many
                    thanks to Anna. At time of writing, Dr. Wang is a professor
                    of computer science at HKUST, and Anna is a cryptography
                    researcher at the University of Chicago.
				</p>

                <p>
                    It all started in the Winter of 2016. My friend
                    <a href="https://www.chosenplaintext.ca/">Tim McLean</a>
                    and I were bored and looking for something to do, and we
                    start playing around with some ideas about website
                    fingerprinting. Tim's a security engineer, primarily, and
                    had been spending a lot of his time in those days reading
                    about side-channel attacks. HTTP/2 had only come out that
                    past May. There was a lot to be learned by civilians like
                    me about how information was transferred over the internet
                    in the first place, let alone in this new framework. We had
                    some notion about being able to identify websites from
                    their packet sizes, in load-order.
                </p>
                
                <p>
                    Now, I don't really know the first thing about internet
                    protocol or transmission control protocol, or much about
                    networking generally. But what I did have was a working
                    understanding of statistical modelling and a bit of time on
                    my hands. I still don't have much grasp on the technological
                    points, so if what I write has some errors in it, it will
                    not come as a shock to me (and if you spot one or many, do
                    let me know).
                </p>

                <p>
                    My understanding is that as a webpage is loaded, it calls
                    things in a particular order. First, you might have some
                    site or process-specific overhead, things like decal
                    formatting or navicons or things of that nature that don't
                    change from page to page but must be loaded with each. That
                    might be some html and then some associated CSS, javascript,
                    and media. The html needs to come in first, because it's
                    what dictates where everything else goes. The other items
                    just get called. If that's right, it explains why on a poor
                    load-job you get a very bare-bones looking white page with
                    no formatting and big walls of text.
                </p>

                <p>
                    Tim, for his part, wrote a script for us to load the web
                    pages and collect the traffic data &mdash; so for our
                    purposes, that included the URLs and the packets, as well
                    as the time and date at which we collected them. We then
                    assembled that into a database. This database would be used
                    to compare with the data collected from an unwitting target.
                    That target data wouldn't include the URL's and wouldn't
                    have the date and time associated with it. All that would
                    be available to the attacker would be the target's packet
                    sizes, and what website they were on (but not which specific
                    page). I'll explain the approach we took both in words and
                    also with a pretty diagram.
                </p>

                <div class="image">
                    <p style="text-align:center;">
                        <img src="scheme.png"
                        alt="Diagrammatic description of our
                        statistical attack process" class="image">
                    </p>
                </div>

                <p>
                    In point of fact, this diagram details more than I managed
                    to accomplish before finding out we'd gotten scooped before
                    even beginning. I never got around to doing page-view
                    correlations, but I imagine I would've tried to see which
                    articles might have linked to eachother or maybe have come
                    up with some categorization scheme following that which many
                    wiki articles already dutifully provide. The frequency
                    analysis would have been the last-ditch attempt to increase
                    accuracy, based solely on which pages were more popular to
                    provide the best guess. We probably would have only used
                    that in the unlikely event of a tie.
                </p>

                <p>
                    As for the direct matching, I wrote a few scripts that did
                    a post-processing on the URL's to make sure that they
                    would be the same length (so that we might compare pages
                    sans media to pages which included images, sound, and/or
                    video) to those without. Then I put those vectors, now
                    usually something like 13-dimensional into a
                    cosine-similarity test. After a bit of tweaking one
                    Saturday night a couple weeks ago, I'd managed to get a
                    match rate of just over 30&percnt; between a database and
                    some generated target data collected 6 months apart from
                    each other. That was an exciting result. We'd spent some
                    time on this over the years, a few late nights here and
                    there, a few hours tinkering away getting the code together,
                    me getting myself familiar with LaTeX-ing a proper article
                    in many columns! It was nice to think that maybe it would go
                    somewhere after all. We even had a title agreed upon, we
                    were gonna call the paper "<i>Handshake the Devil:
                    Statistical Analysis of TLS Traffic Records and
                    Cryptanalytic Implications</i>". But alas...
                </p>

                <p>    
                    I asked Anna if she thought this was a direction worth
                    moonlighting on. She was encouraging, but followed up
                    fairly quickly with the thesis linked above and all hopes
                    were dashed. According to her, and she is an authority,
                    the environment for website fingerprinting attack research
                    is mostly along the lines of machine learning these days.
                    I've got no serious background in ML, so that's a bridge
                    too far for the time being &mdash; and I expect by the
                    time I've got cause to learn enough, the avenue will be
                    explored. So for the first time, I took all the data and
                    all the code we wrote, and all the papers we read over
                    those 5 years, and I put them on a usb which now rests in
                    a box in the deep of my own desk drawer. It's a sad but
                    relieving feeling to put something like that away.  I'll
                    be holding onto some of the nice memories of our working
                    sessions, as well as much of the knowledge I gained, for
                    quite some time.
                </p>

            </div>
        </div>
        <!-- /post -->
    </div>
</div>

<footer>
	<div class="container">
		<div class="units-row">
			<div class="unit-100">
                <center>
				<ul class="social list-flat">
					<li><a href="mailto:will@wgertler.com"><i class="fa-regular fa-envelope"></i></a></li>
					<li><a href="https://github.com/swickrotation"><i class="fa-brands fa-square-github"></i></a></li>
t					<li><a href="https://linkedin.com/in/swickrotation/"><i class="fa-brands fa-linkedin"></i></a></li>
					<li><a href="https://stackoverflow.com/users/4305163/swickrotation"><i class="fa-brands fa-stack-overflow"></i></a></li>
					<li><a href="http://twitter.com/swickrotation"><i class="fa-brands fa-x-twitter"></i></a></li>
				</ul>
                </center>
			</div>
		</div>
	</div>
</footer>

<!-- Javascript -->
<script src="/js/jquery.js"></script>
<script src="/js/kube.js"></script>
</body>
</html>
